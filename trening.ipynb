{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dbd9j7mXOHfG",
        "outputId": "de1a56f3-ac1d-4eb2-d1a2-6092a72bbbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 150.5249, Accuracy: 37.40%, Validation Accuracy: 47.83%\n",
            "Epoch 2/100, Loss: 101.2157, Accuracy: 53.82%, Validation Accuracy: 57.00%\n",
            "Epoch 3/100, Loss: 82.9977, Accuracy: 61.63%, Validation Accuracy: 62.96%\n",
            "Epoch 4/100, Loss: 69.4978, Accuracy: 67.18%, Validation Accuracy: 60.57%\n",
            "Epoch 5/100, Loss: 61.2572, Accuracy: 70.67%, Validation Accuracy: 73.94%\n",
            "Epoch 6/100, Loss: 54.1048, Accuracy: 73.87%, Validation Accuracy: 73.65%\n",
            "Epoch 7/100, Loss: 42.1505, Accuracy: 80.80%, Validation Accuracy: 77.11%\n",
            "Epoch 8/100, Loss: 34.2785, Accuracy: 84.22%, Validation Accuracy: 77.94%\n",
            "Epoch 9/100, Loss: 31.4346, Accuracy: 85.83%, Validation Accuracy: 89.75%\n",
            "Epoch 10/100, Loss: 19.4540, Accuracy: 92.52%, Validation Accuracy: 93.27%\n",
            "Epoch 11/100, Loss: 15.6253, Accuracy: 94.21%, Validation Accuracy: 94.14%\n",
            "Epoch 12/100, Loss: 17.1573, Accuracy: 93.52%, Validation Accuracy: 93.12%\n",
            "Epoch 13/100, Loss: 12.3541, Accuracy: 95.39%, Validation Accuracy: 94.24%\n",
            "Epoch 14/100, Loss: 9.5466, Accuracy: 96.55%, Validation Accuracy: 92.97%\n",
            "Epoch 15/100, Loss: 6.2335, Accuracy: 98.15%, Validation Accuracy: 98.44%\n",
            "Epoch 16/100, Loss: 10.0277, Accuracy: 96.10%, Validation Accuracy: 97.66%\n",
            "Epoch 17/100, Loss: 4.3762, Accuracy: 98.61%, Validation Accuracy: 97.51%\n",
            "Epoch 18/100, Loss: 3.8025, Accuracy: 98.78%, Validation Accuracy: 96.05%\n",
            "Epoch 19/100, Loss: 4.6895, Accuracy: 98.07%, Validation Accuracy: 98.58%\n",
            "Epoch 20/100, Loss: 5.7234, Accuracy: 97.84%, Validation Accuracy: 96.58%\n",
            "Epoch 21/100, Loss: 3.4900, Accuracy: 98.93%, Validation Accuracy: 98.78%\n",
            "Epoch 22/100, Loss: 7.5531, Accuracy: 97.17%, Validation Accuracy: 98.73%\n",
            "Epoch 23/100, Loss: 2.7399, Accuracy: 99.23%, Validation Accuracy: 99.37%\n",
            "Epoch 24/100, Loss: 1.4051, Accuracy: 99.68%, Validation Accuracy: 98.93%\n",
            "Epoch 25/100, Loss: 1.3429, Accuracy: 99.61%, Validation Accuracy: 99.56%\n",
            "Epoch 26/100, Loss: 0.9405, Accuracy: 99.78%, Validation Accuracy: 99.51%\n",
            "Epoch 27/100, Loss: 5.2823, Accuracy: 97.91%, Validation Accuracy: 98.34%\n",
            "Epoch 28/100, Loss: 1.5123, Accuracy: 99.61%, Validation Accuracy: 99.41%\n",
            "Epoch 29/100, Loss: 0.6054, Accuracy: 99.93%, Validation Accuracy: 99.56%\n",
            "Epoch 30/100, Loss: 0.8360, Accuracy: 99.78%, Validation Accuracy: 98.78%\n",
            "Epoch 31/100, Loss: 4.1002, Accuracy: 98.34%, Validation Accuracy: 98.54%\n",
            "Epoch 32/100, Loss: 4.3678, Accuracy: 98.29%, Validation Accuracy: 96.44%\n",
            "Epoch 33/100, Loss: 2.5879, Accuracy: 99.05%, Validation Accuracy: 98.83%\n",
            "Epoch 34/100, Loss: 0.7702, Accuracy: 99.82%, Validation Accuracy: 99.71%\n",
            "Epoch 35/100, Loss: 0.7490, Accuracy: 99.84%, Validation Accuracy: 99.71%\n",
            "Epoch 36/100, Loss: 0.4897, Accuracy: 99.85%, Validation Accuracy: 99.80%\n",
            "Epoch 37/100, Loss: 1.1396, Accuracy: 99.65%, Validation Accuracy: 99.12%\n",
            "Epoch 38/100, Loss: 15.9685, Accuracy: 94.15%, Validation Accuracy: 97.56%\n",
            "Epoch 39/100, Loss: 2.0136, Accuracy: 99.30%, Validation Accuracy: 99.71%\n",
            "Epoch 40/100, Loss: 0.7954, Accuracy: 99.77%, Validation Accuracy: 99.66%\n",
            "Epoch 41/100, Loss: 0.3414, Accuracy: 99.98%, Validation Accuracy: 99.71%\n",
            "Epoch 42/100, Loss: 0.3763, Accuracy: 99.95%, Validation Accuracy: 99.71%\n",
            "Epoch 43/100, Loss: 0.2294, Accuracy: 99.93%, Validation Accuracy: 99.76%\n",
            "Epoch 44/100, Loss: 0.2193, Accuracy: 99.95%, Validation Accuracy: 99.76%\n",
            "Epoch 45/100, Loss: 0.1735, Accuracy: 99.99%, Validation Accuracy: 99.46%\n",
            "Epoch 46/100, Loss: 0.2126, Accuracy: 99.95%, Validation Accuracy: 99.71%\n",
            "Epoch 47/100, Loss: 0.1294, Accuracy: 99.99%, Validation Accuracy: 99.76%\n",
            "Epoch 48/100, Loss: 0.1831, Accuracy: 99.96%, Validation Accuracy: 99.71%\n",
            "Epoch 49/100, Loss: 0.0979, Accuracy: 100.00%, Validation Accuracy: 99.85%\n",
            "Epoch 50/100, Loss: 0.2193, Accuracy: 99.95%, Validation Accuracy: 99.71%\n",
            "Epoch 51/100, Loss: 0.7845, Accuracy: 99.71%, Validation Accuracy: 97.95%\n",
            "Epoch 52/100, Loss: 25.3571, Accuracy: 91.95%, Validation Accuracy: 98.73%\n",
            "Epoch 53/100, Loss: 1.2580, Accuracy: 99.73%, Validation Accuracy: 99.37%\n",
            "Epoch 54/100, Loss: 1.0433, Accuracy: 99.74%, Validation Accuracy: 99.51%\n",
            "Epoch 55/100, Loss: 0.3504, Accuracy: 99.99%, Validation Accuracy: 99.80%\n",
            "Epoch 56/100, Loss: 0.2012, Accuracy: 100.00%, Validation Accuracy: 99.66%\n",
            "Epoch 57/100, Loss: 0.3336, Accuracy: 99.89%, Validation Accuracy: 99.51%\n",
            "Epoch 58/100, Loss: 10.7346, Accuracy: 96.48%, Validation Accuracy: 99.56%\n",
            "Epoch 59/100, Loss: 1.3296, Accuracy: 99.59%, Validation Accuracy: 99.27%\n",
            "Epoch 60/100, Loss: 0.3098, Accuracy: 99.99%, Validation Accuracy: 99.85%\n",
            "Epoch 61/100, Loss: 0.1715, Accuracy: 99.99%, Validation Accuracy: 99.76%\n",
            "Epoch 62/100, Loss: 0.8912, Accuracy: 99.71%, Validation Accuracy: 99.46%\n",
            "Epoch 63/100, Loss: 0.7443, Accuracy: 99.77%, Validation Accuracy: 99.71%\n",
            "Epoch 64/100, Loss: 0.1294, Accuracy: 100.00%, Validation Accuracy: 99.80%\n",
            "Epoch 65/100, Loss: 0.1162, Accuracy: 99.98%, Validation Accuracy: 99.76%\n",
            "Epoch 66/100, Loss: 0.0718, Accuracy: 100.00%, Validation Accuracy: 99.85%\n",
            "Epoch 67/100, Loss: 0.0597, Accuracy: 100.00%, Validation Accuracy: 99.85%\n",
            "Epoch 68/100, Loss: 0.0822, Accuracy: 99.98%, Validation Accuracy: 99.76%\n",
            "Epoch 69/100, Loss: 0.0909, Accuracy: 99.99%, Validation Accuracy: 99.46%\n",
            "Epoch 70/100, Loss: 0.7261, Accuracy: 99.65%, Validation Accuracy: 98.44%\n",
            "Epoch 71/100, Loss: 4.5764, Accuracy: 98.28%, Validation Accuracy: 94.73%\n",
            "Epoch 72/100, Loss: 8.6839, Accuracy: 96.84%, Validation Accuracy: 99.71%\n",
            "Epoch 73/100, Loss: 0.2769, Accuracy: 99.99%, Validation Accuracy: 99.85%\n",
            "Epoch 74/100, Loss: 0.2381, Accuracy: 99.94%, Validation Accuracy: 99.85%\n",
            "Epoch 75/100, Loss: 0.1398, Accuracy: 99.99%, Validation Accuracy: 99.90%\n",
            "Epoch 76/100, Loss: 0.1155, Accuracy: 99.99%, Validation Accuracy: 99.90%\n",
            "Epoch 77/100, Loss: 0.0853, Accuracy: 99.99%, Validation Accuracy: 99.90%\n",
            "Epoch 78/100, Loss: 0.0867, Accuracy: 99.98%, Validation Accuracy: 99.90%\n",
            "Epoch 79/100, Loss: 0.0643, Accuracy: 99.99%, Validation Accuracy: 99.80%\n",
            "Epoch 80/100, Loss: 0.0420, Accuracy: 100.00%, Validation Accuracy: 99.85%\n",
            "Epoch 81/100, Loss: 0.0639, Accuracy: 100.00%, Validation Accuracy: 99.76%\n",
            "Epoch 82/100, Loss: 0.3506, Accuracy: 99.91%, Validation Accuracy: 99.85%\n",
            "Epoch 83/100, Loss: 0.0461, Accuracy: 100.00%, Validation Accuracy: 99.85%\n",
            "Epoch 84/100, Loss: 0.2990, Accuracy: 99.89%, Validation Accuracy: 99.85%\n",
            "Epoch 85/100, Loss: 0.3358, Accuracy: 99.93%, Validation Accuracy: 99.61%\n",
            "Epoch 86/100, Loss: 0.6324, Accuracy: 99.83%, Validation Accuracy: 99.66%\n",
            "Epoch 87/100, Loss: 6.5352, Accuracy: 97.73%, Validation Accuracy: 96.58%\n",
            "Epoch 88/100, Loss: 3.5210, Accuracy: 98.76%, Validation Accuracy: 98.34%\n",
            "Epoch 89/100, Loss: 0.7937, Accuracy: 99.77%, Validation Accuracy: 99.56%\n",
            "Epoch 90/100, Loss: 0.8859, Accuracy: 99.68%, Validation Accuracy: 99.85%\n",
            "Epoch 91/100, Loss: 2.0279, Accuracy: 99.18%, Validation Accuracy: 99.66%\n",
            "Epoch 92/100, Loss: 0.6298, Accuracy: 99.78%, Validation Accuracy: 99.51%\n",
            "Epoch 93/100, Loss: 0.0659, Accuracy: 100.00%, Validation Accuracy: 99.95%\n",
            "Epoch 94/100, Loss: 0.0257, Accuracy: 100.00%, Validation Accuracy: 99.95%\n",
            "Epoch 95/100, Loss: 0.0235, Accuracy: 100.00%, Validation Accuracy: 99.90%\n",
            "Epoch 96/100, Loss: 0.0258, Accuracy: 100.00%, Validation Accuracy: 99.95%\n",
            "Epoch 97/100, Loss: 0.0188, Accuracy: 100.00%, Validation Accuracy: 99.95%\n",
            "Epoch 98/100, Loss: 0.0190, Accuracy: 100.00%, Validation Accuracy: 99.95%\n",
            "Epoch 99/100, Loss: 0.0149, Accuracy: 100.00%, Validation Accuracy: 99.95%\n",
            "Epoch 100/100, Loss: 0.0163, Accuracy: 100.00%, Validation Accuracy: 99.95%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Importujemy wymagane biblioteki\n",
        "import os\n",
        "import urllib.request\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "import csv\n",
        "\n",
        "# Parametry\n",
        "patch_size = 16\n",
        "\n",
        "# Funkcja do pobierania plików\n",
        "def download_file(url, filename):\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Pobieranie {filename}...\")\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "        print(f\"Pobrano {filename}\")\n",
        "\n",
        "# Ładowanie danych\n",
        "def load_indian_pines():\n",
        "    data_url = \"https://www.ehu.eus/ccwintco/uploads/6/67/Indian_pines_corrected.mat\"\n",
        "    label_url = \"https://www.ehu.eus/ccwintco/uploads/c/c4/Indian_pines_gt.mat\"\n",
        "    data_file = \"Indian_pines_corrected.mat\"\n",
        "    label_file = \"Indian_pines_gt.mat\"\n",
        "    download_file(data_url, data_file)\n",
        "    download_file(label_url, label_file)\n",
        "    data = sio.loadmat(data_file)[\"indian_pines_corrected\"]\n",
        "    labels = sio.loadmat(label_file)[\"indian_pines_gt\"]\n",
        "    return data, labels\n",
        "\n",
        "# Normalizacja\n",
        "def normalize(data):\n",
        "    h, w, b = data.shape\n",
        "    data = data.reshape(-1, b)\n",
        "    data = MinMaxScaler().fit_transform(data)\n",
        "    return data.reshape(h, w, b)\n",
        "\n",
        "# Padding\n",
        "def pad_with_zeros(data, margin):\n",
        "    return np.pad(data, ((margin, margin), (margin, margin), (0, 0)), mode='constant')\n",
        "\n",
        "# Dataset\n",
        "class HSI_Dataset(Dataset):\n",
        "    def __init__(self, patch_size=patch_size):\n",
        "        data, labels = load_indian_pines()\n",
        "        data = normalize(data)\n",
        "        margin = patch_size // 2\n",
        "        padded_data = pad_with_zeros(data, margin)\n",
        "\n",
        "        h, w, _ = data.shape\n",
        "        self.patches = []\n",
        "        self.targets = []\n",
        "\n",
        "        for i in range(h):\n",
        "            for j in range(w):\n",
        "                label = labels[i, j]\n",
        "                if label == 0:\n",
        "                    continue\n",
        "                patch = padded_data[i:i+patch_size, j:j+patch_size, :]\n",
        "                self.patches.append(patch)\n",
        "                self.targets.append(label - 1)\n",
        "\n",
        "        self.patches = np.array(self.patches)\n",
        "        self.patches = np.transpose(self.patches, (0, 3, 1, 2))  # (N, B, H, W)\n",
        "        self.targets = np.array(self.targets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patches)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.patches[idx], dtype=torch.float32), torch.tensor(self.targets[idx], dtype=torch.long)\n",
        "\n",
        "# Loadery\n",
        "def get_loaders(batch_size=32, patch_size=patch_size, val_split=0.2):\n",
        "    dataset = HSI_Dataset(patch_size)\n",
        "    val_len = int(len(dataset) * val_split)\n",
        "    train_len = len(dataset) - val_len\n",
        "    train_set, val_set = random_split(dataset, [train_len, val_len])\n",
        "    return DataLoader(train_set, batch_size=batch_size, shuffle=True), DataLoader(val_set, batch_size=batch_size)\n",
        "\n",
        "# CNN z diagramu\n",
        "class CNNFromDiagram(nn.Module):\n",
        "    def __init__(self, input_channels=200, num_classes=16, patch_size=16):\n",
        "        super(CNNFromDiagram, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=100, kernel_size=3)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=100, out_channels=100, kernel_size=3)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Oblicz rozmiar wyjścia po konwolucjach\n",
        "        dummy_input = torch.zeros(1, input_channels, patch_size, patch_size)\n",
        "        x = self.pool1(F.relu(self.conv1(dummy_input)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        flatten_dim = x.view(1, -1).shape[1]  # <-- to oblicza prawidłowy rozmiar\n",
        "\n",
        "        self.fc1 = nn.Linear(flatten_dim, 84)\n",
        "        self.fc2 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Trenowanie\n",
        "def train(model, train_loader, val_loader, epochs=10, lr=0.001, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    with open(\"training_log.csv\", mode=\"w\", newline=\"\") as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Epoch\", \"Train Loss\", \"Train Accuracy\", \"Validation Accuracy\"])\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            total_loss, correct = 0, 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "                correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "            acc = 100.0 * correct / len(train_loader.dataset)\n",
        "\n",
        "            model.eval()\n",
        "            val_correct = 0\n",
        "            with torch.no_grad():\n",
        "                for val_inputs, val_labels in val_loader:\n",
        "                    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "                    val_outputs = model(val_inputs)\n",
        "                    val_correct += (val_outputs.argmax(1) == val_labels).sum().item()\n",
        "            val_acc = 100.0 * val_correct / len(val_loader.dataset)\n",
        "\n",
        "            writer.writerow([epoch + 1, total_loss, acc, val_acc])\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, Accuracy: {acc:.2f}%, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "# Predykcja całej sceny\n",
        "def predict_whole_scene(model, patch_size=16, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    data, labels = load_indian_pines()\n",
        "    data = normalize(data)\n",
        "    h, w, b = data.shape\n",
        "    margin = patch_size // 2\n",
        "    padded_data = pad_with_zeros(data, margin)\n",
        "    output = np.zeros((h, w), dtype=np.uint8)\n",
        "\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            if labels[i, j] == 0:\n",
        "                continue\n",
        "            patch = padded_data[i:i+patch_size, j:j+patch_size, :]\n",
        "            patch = np.expand_dims(patch, axis=0)\n",
        "            patch = np.transpose(patch, (0, 3, 1, 2))  # (1, B, H, W)\n",
        "            patch = torch.tensor(patch, dtype=torch.float32).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                pred = model(patch)\n",
        "                output[i, j] = pred.argmax(1).item() + 1  # +1 by pasowało do etykiet\n",
        "\n",
        "    return output, labels\n",
        "\n",
        "# Wizualizacja\n",
        "def visualize(pred_map, true_map):\n",
        "    class_names = [\n",
        "        \"Background\", \"Alfalfa\", \"Corn-notill\", \"Corn-mintill\", \"Corn\",\n",
        "        \"Grass-pasture\", \"Grass-trees\", \"Grass-pasture-mowed\", \"Hay-windrowed\",\n",
        "        \"Oats\", \"Soybean-notill\", \"Soybean-mintill\", \"Soybean-clean\",\n",
        "        \"Wheat\", \"Woods\", \"Buildings-Grass-Trees-Drives\", \"Stone-Steel-Towers\"\n",
        "    ]\n",
        "\n",
        "    cmap = ListedColormap([\n",
        "        (0, 0, 0), (0.6, 0, 0), (0, 0.6, 0), (0, 0, 0.6), (0.6, 0.6, 0),\n",
        "        (0.6, 0, 0.6), (0, 0.6, 0.6), (0.9, 0.3, 0.1), (0.1, 0.5, 0.9),\n",
        "        (0.7, 0.2, 0.7), (0.2, 0.7, 0.2), (0.9, 0.9, 0), (0.3, 0.3, 0.3),\n",
        "        (0.5, 0.2, 0.2), (0.2, 0.5, 0.2), (0.2, 0.2, 0.5), (1.0, 1.0, 1.0)\n",
        "    ])\n",
        "\n",
        "    norm = BoundaryNorm(boundaries=np.arange(17) - 0.5, ncolors=17)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    axs[0].imshow(true_map, cmap=cmap, norm=norm)\n",
        "    axs[0].set_title(\"Ground Truth\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    axs[1].imshow(pred_map, cmap=cmap, norm=norm)\n",
        "    axs[1].set_title(\"Predicted Map\")\n",
        "    axs[1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    patches = [mpatches.Patch(color=cmap(i), label=f\"{i}: {class_names[i]}\")\n",
        "               for i in range(1, len(class_names))]\n",
        "    fig.legend(handles=patches, loc='center right', bbox_to_anchor=(1.15, 0.5), title=\"Classes\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Główne wywołanie\n",
        "if __name__ == \"__main__\":\n",
        "    train_loader, val_loader = get_loaders(batch_size=100, patch_size=patch_size)\n",
        "    model = CNNFromDiagram(input_channels=200, num_classes=16, patch_size=patch_size)\n",
        "    train(model, train_loader, val_loader, epochs=100)\n",
        "    pred_map, true_map = predict_whole_scene(model, patch_size=patch_size)\n",
        "    visualize(pred_map, true_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NRZEnHWwvybp"
      }
    }
  ]
}